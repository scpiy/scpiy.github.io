I"<h3 id="送给初学者的python爬虫教程">送给初学者的python爬虫教程</h3>

<hr />

<p><strong>在看本片教程之前最好有一点点编程语言基础，如果是python基础就更好了，不需要很多关于python的知识，但希望你至少对下面这些概念有个了解</strong></p>

<ul>
  <li>列表(list)</li>
  <li>字典(dict)</li>
  <li>模块(只要知道这是个什么就好，不用太了解)</li>
  <li>基础的控制语句，比如if，for</li>
</ul>

<p>如果你对上面我说的东西一头雾水，建议你可以看看<a href="https://www.liaoxuefeng.com/wiki/1016959663602400">Python教程</a>，廖雪峰老师的python教程，不用都学完，倒不如说只看一点就可以，对python有一点点了解就可以。</p>

<p>这个简单的入门教程会用到如下几个库</p>

<ul>
  <li>requests</li>
  <li>BeautifulSoup</li>
</ul>

<p>分别可以在命令行通过如下命令安装(windows)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install requests
pip install bs4
</code></pre></div></div>

<blockquote>
  <p>顺便说一下，可能有的人用的不是requests库，而是urllib或是其他的什么，简单说一下他们的区别的话，就是requests更年轻，也更方便，更适合新手，还有BeautifulSoup已经迁移到bs4里了，所以可以直接安装bs4，这样就可以使用BeautifulSoup了</p>
</blockquote>

<p>然后说一下这两个库的作用，requests库的作用是得到目标网页的内容，可以通过</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">request</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</code></pre></div></div>

<p>实现，url就是我们要解析的网页网址</p>

<p>至于BeautifulSoup，是一个十分方便的，可以帮我们在一堆HTML代码里面找到我们想要的内容的库</p>

<p>今天我只是简单用一下，对他们的功能进行简要介绍，你大概了解就好，之后会比较详细的说一下的</p>

<p>我们今天来爬一下最近很火的国漫电影《哪吒》的短评，首先打开对应的网页</p>

<p><img src="https://s2.ax1x.com/2019/08/07/e5c0FH.png" alt="哪吒短评" /></p>

<p>建议使用chrome浏览器，好处太多，重点是方便我们写爬虫，如果不是chrome的话，可以自己百度打开网页源码的方式。</p>

<p>下面的东西对于没有了解过HTML的人来说可能有些不友好，但也不是不能看，如果你真的不会HTML，可以先用我找出来的路径，<del>复制粘贴总会吧，</del>把重点放在爬虫程序的构建上。</p>

<p><a href="https://imgchr.com/i/e5gvb8"><img src="https://s2.ax1x.com/2019/08/07/e5gvb8.md.png" alt="e5gvb8.md.png" /></a></p>

<p>可以看出来我们要找的东西都在class = “short”的span下，知道这个就好办了</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s">"User-Agent"</span><span class="p">:</span> <span class="s">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36"</span><span class="p">}</span>
<span class="c1">#这个headers，你暂时不用管它是什么，之后会说，现在跟着我做就好
</span><span class="n">url</span> <span class="o">=</span> <span class="s">"https://movie.douban.com/subject/26794435/comments?limit=20&amp;sort=new_score&amp;status=P"</span>
<span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1">#"https://movie.douban.com/subject/26794435/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P"
#这是网页本来的url，经过观察发现，每次翻页那个start的值都会加20，可以利用这个机制实现类似翻页的功能
</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"test.txt"</span><span class="p">,</span> <span class="s">'a'</span><span class="p">,</span> <span class="n">encoding</span> <span class="o">=</span> <span class="s">"utf8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
    <span class="c1">#打开一个文件，with语句可以不用管，就像正常打开一个文件也可以，使用with只是我的习惯
</span>    <span class="c1">#先爬5页，大概就是100条内容
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">html</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">"start"</span><span class="p">:</span> <span class="n">start</span><span class="p">})</span>
        <span class="n">start</span> <span class="o">+=</span> <span class="mi">20</span>
        <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">.</span><span class="n">text</span><span class="p">,</span> <span class="s">"lxml"</span><span class="p">)</span>
        <span class="c1">#html.text是获得名为html的对象的内容
</span>        <span class="k">for</span> <span class="n">comment</span> <span class="ow">in</span> <span class="n">soup</span><span class="p">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">"span"</span><span class="p">,</span> <span class="n">class_</span> <span class="o">=</span> <span class="s">"short"</span><span class="p">):</span>
            <span class="n">fp</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">comment</span><span class="p">.</span><span class="n">text</span> <span class="o">+</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="c1">#find_all会返回找到的所有的匹配对象
</span>        <span class="c1">#把匹配到的对象(也就是我们要找的东西)的内容写到文件里，完工
</span></code></pre></div></div>

<p>最好自己写写代码，但也可以复制粘贴我的代码，作为入门的第一课，没必要对自己太严格。</p>

<p>大概就这样了，我甚至没有写函数……</p>

<p>今天简要介绍了下requests与BeautifulSoup，想要学好爬虫不仅仅这两个库要会用，lxml，正则最好都要会，虽然BeautifulSoup，lxml，正则的作用大致一样，但在应用上还是有差异的，这个之后我再说吧。</p>

<p>还有HTML，最好是会一点，不会倒也可以，只要你不觉得写正则麻烦并且自信自己正则过关。也不难，去W3school<a href="https://www.w3school.com.cn/html/index.asp">HTML教程</a>看半个小时大概就可以了，又不是让你写前端，有个概念就行了。</p>

<p>那么，今天就到这里了。</p>

<p>感谢你的观看，希望能对你有帮助。</p>

<p>如果有自己解决不了的问题可以联系我。</p>
:ET